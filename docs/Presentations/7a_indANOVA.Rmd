---
title: "One-Factor ANOVA"
subtitle: "Between-subjects designs"
author: "Matthew Crump"
date: "2018/07/20 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: ["defaultb.css", "metropolisb.css", "metropolis-fontsb.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE,message=FALSE,warning=FALSE, cache = TRUE)
```

class: pink, center, middle, clear

# ANOVAs

---

# Overview

1. ANOVA concepts
2. one-factor between subjects example

- Look at the last few slides for quiz tips (using R)

---

# ANOVA

ANOVA stands for ANalysis Of VAriance

---

# Purpose of ANOVA

1. Statistical inference test for multiple (2 or more)  groups
2. The kind of ANOVA you run depends on the experimental design. This week we focus on **Between-Subjects designs**

---

# Heads up

The end result of an ANOVA gives back similar information as a t-test

1. t(df) = t-value, p = p-value
2. F(df1, df2) = F-value, p = value

Reporting of F-tests also typically include one more thing:

3. F(df1, df2) = F-value, MSE = MS error value, p = value

---

# Fast Example

```{r, echo=T, cache=F}
A <- c(20,11,2)
B <- c(6,2,7)
C <- c(2,11,2)
IV <- as.factor(rep(c("A","B","C"),each=3))
DV <- c(A,B,C)
df <- data.frame(IV,DV)
```

---

# R: aov()

```{r, echo=T, cache=F}
aov(DV~IV,df)
```

---

# R: summary()

The `summary()` function provides the ANOVA table

```{r, echo=T, cache=F}
aov_results <- aov(DV~IV,df)
summary(aov_results)
```

---

# Things we need to understand

1. The logic of the ANOVA
2. What each part of the ANOVA table tells us

Let's start by looking at the example for the next lab on ANOVA.

---

# ANOVA lab example

```{r}
knitr::include_graphics("figs/anova1/lab1.png")
```


---

class: center, middle, clear, nopad

```{r, out.width="80%"}
knitr::include_graphics("figs/anova1/lab2.png")
```

---

# Results

```{r, out.width="50%"}
knitr::include_graphics("figs/anova1/lab3.png")
```

---

# Write-up

```{r}
knitr::include_graphics("figs/anova1/lab4.png")
```

---

# Things we need to understand

1. The logic of the ANOVA
2. What each part of the ANOVA table tells us

---

# ANOVA is an omnibus test

- Omnibus definition: comprising many items

- ANOVAs can test for differences among many means (2 or more)

- Test question: Are there any differences among the means?

- If the answer is yes, then we still do not know which specific means are different from one another.




---

# F-value

F is a ratio between two variances

```{r,cache=F}
summary(aov_results)
```

$F=\frac{\text{MSE}_\text{Effect}}{\text{MSE}_\text{Error}}$
$F=\frac{\text{Mean Squared Error}_\text{IV}}{\text{Mean Squared Error}_\text{Residuals}}$
```{r,echo=T}
36/38.33
```

---

# MSE: Mean squared Error (effect)

MSE (Mean Squared Error) is the SS (sums of sqaures) divided by the degrees of freedom

```{r, cache=F}
summary(aov_results)
```

$\text{MSE}_\text{Effect}=\frac{\text{SS}_\text{Effect}}{\text{df}_\text{Effect}}$
$\text{MSE}_\text{IV}=\frac{\text{SS}_\text{IV}}{\text{df}_\text{IV}}$

```{r,echo=T}
72/2
```

---

# MSE: Mean squared Error (error)

MSE (Mean Squared Error) is the SS (sums of sqaures) divided by the degrees of freedom

```{r, cache=F}
summary(aov_results)
```

$\text{MSE}_\text{Error}=\frac{\text{SS}_\text{Error}}{\text{df}_\text{Error}}$
$\text{MSE}_\text{Residuals}=\frac{\text{SS}_\text{Residuals}}{\text{df}_\text{Residuals}}$

```{r,echo=T}
6/230
```

---

# ANOVA reference table

```{r}
knitr::include_graphics("figs/anova1/aov_formula.png")
```

---

class: pink, center, middle, clear

# The big idea

---

# Partitioning the Variance

Idea is to split up the variance in the data into two parts:

1. The part due to the manipulation (IV)
2. The leftover part, due to random error

---

class: center, middle, clear, nopad


```{r}
knitr::include_graphics("figs/anova1/aovlec.001.png")
```

---

class: center, middle, clear, nopad


```{r}
knitr::include_graphics("figs/anova1/aovlec.002.png")
```

---

class: center, middle, clear, nopad


```{r}
knitr::include_graphics("figs/anova1/aovlec.003.png")
```

---

class: center, middle, clear, nopad


```{r}
knitr::include_graphics("figs/anova1/aovlec.004.png")
```

---

class: center, middle, clear, nopad


```{r}
knitr::include_graphics("figs/anova1/aovlec.005.png")
```

---

class: center, middle, clear, nopad


```{r}
knitr::include_graphics("figs/anova1/aovlec.006.png")
```

---

class: center, middle, clear, nopad


```{r}
knitr::include_graphics("figs/anova1/aovlec.007.png")
```

---

class: center, middle, clear, nopad


```{r}
knitr::include_graphics("figs/anova1/aovlec.008.png")
```

---

class: center, middle, clear, nopad


```{r}
knitr::include_graphics("figs/anova1/aovlec.009.png")
```

---

class: center, middle, clear, nopad


```{r}
knitr::include_graphics("figs/anova1/aovlec.010.png")
```

---

# SS total

$SS_\text{Total} = SS_\text{Effect} + SS_\text{Error}$

$SS_\text{Total} = SS_\text{Can Explain} + SS_\text{Can't Explain}$

$SS_\text{Total} = SS_\text{Change due to manipulation} + SS_\text{Change due to Chance}$

$SS_\text{Total} = \sum_{i=1}^n(x_{i}-\bar{X})^2$

- $x_{i}$ = each score
- $\bar{X}$ = Grand Mean of all scores

---

# SS total example

```{r,out.width="70%"}
knitr::include_graphics("figs/anova1/SS_total.png")
```

---

# R: SS total

$SS_\text{Total} = \sum_{i=1}^n(x_{i}-\bar{X})^2$

- the sum of the squared differences between every score and the grand mean

```{r, echo=T}
A <- c(20,11,2)
B <- c(6,2,7)
C <- c(2,11,2)
all_scores <- c(A,B,C)
grand_mean <- mean(all_scores)
SS_total <- sum((all_scores-grand_mean)^2)
print(SS_total)
```


---

# Remember what SS represents?

SS (the sums of squares) is a single number representing the sum of all of the **change** in the data. 

- Specifically, the squared deviations from each score from the mean

---

# Question

What are some **sources** of change that could cause $SS_\text{Total}$ for a set of data to increase or decrease?

- what properties of the sample data could be changed that would increase or decrease $SS_\text{Total}$?

---

# SS total and the Effect (IV)

A successful manipulation (IV) will cause an effect (e.g., cause differences between the sample means)

**Question**: How can the effect of an IV cause increases or decreases to $SS_\text{Total}$?

---

# SS total and sampling error

Sampling error is due to existing variability in the data.

**Question**: How can the effect of sampling error cause increases or decreases to $SS_\text{Total}$?

---

# The F-distribution

Let's examine some ANOVA concepts by simulation in R.

---

# Quiz help

The next few slides show examples of computing parts of the ANOVA table in R

---

# The entire ANOVA table: Step 1

1. Put the data into a dataframe. One column should code the levels of the IV, and the other column should include the DV

```{r, echo=T, cache=F}
A <- c(20,11,2)
B <- c(6,2,7)
C <- c(2,11,2)
IV <- as.factor(rep(c("A","B","C"),each=3))
DV <- c(A,B,C)
df <- data.frame(IV,DV)
```

---

# The entire ANOVA table: Step 2

```{r, echo=T, cache=F}
summary(aov(DV~IV, df))
```

---

# SS total

The sum of the squared deviations between each score and the grand mean.

```{r, echo=T}
A <- c(20,11,2)
B <- c(6,2,7)
C <- c(2,11,2)
all_scores <- c(A,B,C)
grand_mean <- mean(all_scores)
SS_total <- sum((all_scores-grand_mean)^2)
print(SS_total)
```

---

# SS total using the ANOVA table

Add up both of the Sums of Squares...

```{r, echo=T, cache=F}
summary(aov(DV~IV, df))
```

---

# SS effect

$SS_\text{Effect} = \sum_{i=1}^kn_i(X_{i}-\bar{X})^2$

Each score is treated as it's group mean. Then, all of these "group mean" scores for each subject is subtracted from the grand mean. The SS effect is the sum of these squared deviations.

---

# R: SS effect

```{r, echo=T}
A <- c(20,11,2)
B <- c(6,2,7)
C <- c(2,11,2)
grand_mean <- mean(c(A,B,C))
scores_as_grp_means <- c(rep(mean(A),3),
                           rep(mean(B),3),
                           rep(mean(C),3))
SS_Effect <- sum((scores_as_grp_means-grand_mean)^2)
print(SS_Effect)
```

---

# SS effect from ANOVA table

Or, just look at the Sums of squares in the first row of the ANOVA table (for IV in this case, which represents the effect).

```{r, echo=T, cache=F}
summary(aov(DV~IV, df))
```

---

# SS error

The sum of the squared deviations between each score and it's group mean.

---

# R: SS error

```{r, echo=T}
A <- c(20,11,2)
B <- c(6,2,7)
C <- c(2,11,2)
scores_as_grp_means <- c(rep(mean(A),3),
                           rep(mean(B),3),
                           rep(mean(C),3))
SS_Error <- sum((scores_as_grp_means-c(A,B,C))^2)
print(SS_Error)
```

---

# SS error from ANOVA table

Or, just look at the Sums of squares in the second row of the ANOVA table (for residuals in this case, which represents the error).

```{r, echo=T, cache=F}
summary(aov(DV~IV, df))
```

---

# Getting F and p from ANOVA table

Put the ANOVA summary into a variable

```{r, echo=T, cache=F}
anova_variable <- summary(aov(DV~IV, df))
```

Get F and associated p

```{r, echo=T}
anova_variable[[1]]$`F value`
anova_variable[[1]]$`Pr(>F)`
```

---

# Getting Df, SS, and MS

```{r,, echo=T}
anova_variable[[1]]$Df
anova_variable[[1]]$`Sum Sq`
anova_variable[[1]]$`Mean Sq`
```


---



# Next class: More ANOVA

1. ANOVA quiz begins this afternoon, due Next Tuesday (Nov 6th) @ 11:59pm



